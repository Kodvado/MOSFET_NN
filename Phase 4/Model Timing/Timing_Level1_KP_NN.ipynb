{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25bf009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (X): (50000, 1685)\n",
      "Target shape (y - log-transformed KP): (50000, 1)\n",
      "Number of devices in original test set: 10000\n",
      "Using first 10000 devices from the test set\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Time taken to predict 10000 devices: 1.389 seconds\n",
      "Average predictions per second: 7197.94\n",
      "Average time per prediction: 0.139 milliseconds\n",
      "\n",
      "Accuracy Statistics (KP Prediction Errors in % - Corrected):\n",
      "Mean Error: 9.36%\n",
      "Median Error: 5.61%\n",
      "Standard Deviation: 12.85%\n",
      "Min Error: 0.00%\n",
      "Max Error: 197.93%\n",
      "\n",
      "R² Score: 0.9632\n",
      "MSE: 6.2052e-10\n",
      "RMSE: 2.4910e-05\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error # Added for more metrics\n",
    "\n",
    "# Configuration\n",
    "NUM_DEVICES = 10000  # Adjust as needed\n",
    "\n",
    "# --- Load data ---\n",
    "# Using the same v9 files as specified in the KP PDF [cite: 2]\n",
    "params_df = pd.read_csv('mosfet_params_v9.csv')\n",
    "measurements_df = pd.read_csv('measurements_v9.csv')\n",
    "\n",
    "# --- Preprocess data (Specific to KP model level1_NN_v2_kp.pdf) ---\n",
    "X_list = []\n",
    "y_list = [] # Target list for KP\n",
    "mosfet_ids = []\n",
    "\n",
    "# Create a temporary lookup for W and L from params_df\n",
    "params_lookup = params_df.set_index('MOSFET_ID')\n",
    "\n",
    "grouped = measurements_df.groupby('MOSFET_ID')\n",
    "for mosfet_id, group in grouped:\n",
    "    group_sorted = group.sort_values('meas_index')\n",
    "    if len(group_sorted) == 561:\n",
    "        try:\n",
    "            # Get W and L for this MOSFET ID\n",
    "            W = params_lookup.loc[mosfet_id, 'W']\n",
    "            L = params_lookup.loc[mosfet_id, 'L']\n",
    "            # Get KP and apply log transform [cite: 2]\n",
    "            kp = params_lookup.loc[mosfet_id, 'KP']\n",
    "            y_kp_log = np.log1p(kp)\n",
    "\n",
    "            # Get measurement features\n",
    "            measurement_features = group_sorted[['VGS', 'VDS', 'ID']].values.flatten()\n",
    "\n",
    "            # Concatenate measurement features with W and L [cite: 2]\n",
    "            features = np.concatenate((measurement_features, [W, L]))\n",
    "\n",
    "            X_list.append(features)\n",
    "            y_list.append(y_kp_log) # Append log-transformed KP\n",
    "            mosfet_ids.append(mosfet_id)\n",
    "\n",
    "        except KeyError:\n",
    "            print(f\"Warning: MOSFET_ID {mosfet_id} not found in params_df. Skipping.\")\n",
    "            continue # Skip if MOSFET ID isn't in both files\n",
    "\n",
    "X = np.array(X_list)\n",
    "y = np.array(y_list).reshape(-1, 1) # y now contains log1p(KP)\n",
    "\n",
    "print(f\"Input shape (X): {X.shape}\") # Should be (num_devices, 1685) [cite: 7]\n",
    "print(f\"Target shape (y - log-transformed KP): {y.shape}\")\n",
    "\n",
    "# --- Split data ---\n",
    "# Use the same random_state if comparing to a specific training run\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# We also need the original y_test for final evaluation\n",
    "# Split original KP values (before log transform) for final comparison\n",
    "y_original_kp = np.expm1(y) # Get original KP back from the full log-transformed y\n",
    "_, y_test_original_kp = train_test_split(y_original_kp, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# --- Scale inputs ---\n",
    "input_scaler = StandardScaler()\n",
    "# Fit the input scaler ONLY on the training data\n",
    "X_train_scaled = input_scaler.fit_transform(X_train)\n",
    "# Apply the SAME fitted scaler to the test data\n",
    "X_test_scaled = input_scaler.transform(X_test)\n",
    "\n",
    "# --- Scale outputs (Log-transformed KP) ---\n",
    "output_scaler = StandardScaler()\n",
    "# Fit the output scaler ONLY on the log-transformed training data [cite: 4]\n",
    "y_train_log_scaled = output_scaler.fit_transform(y_train_log)\n",
    "# We need the FITTED output_scaler later for inverse transform\n",
    "\n",
    "# --- Load model ---\n",
    "# Load the specific KP model [cite: 36]\n",
    "model = load_model('mosfet_kp_model_v2.keras')\n",
    "\n",
    "# --- Adjust test set to NUM_DEVICES ---\n",
    "num_test_devices = X_test_scaled.shape[0]\n",
    "print(f\"Number of devices in original test set: {num_test_devices}\")\n",
    "\n",
    "if num_test_devices >= NUM_DEVICES:\n",
    "    X_test_scaled_adjusted = X_test_scaled[:NUM_DEVICES]\n",
    "    # IMPORTANT: Adjust the ORIGINAL KP test set for final comparison\n",
    "    y_test_original_kp_adjusted = y_test_original_kp[:NUM_DEVICES]\n",
    "    print(f\"Using first {NUM_DEVICES} devices from the test set\")\n",
    "elif num_test_devices > 0:\n",
    "    print(f\"Warning: Test set has fewer than {NUM_DEVICES} devices ({num_test_devices}). Using all available.\")\n",
    "    X_test_scaled_adjusted = X_test_scaled\n",
    "    y_test_original_kp_adjusted = y_test_original_kp # Use the original KP y_test\n",
    "    NUM_DEVICES = num_test_devices # Update NUM_DEVICES to actual number used\n",
    "else:\n",
    "    print(\"Error: No devices in the test set.\")\n",
    "    exit()\n",
    "\n",
    "# --- Measure prediction time ---\n",
    "start_time = time.time()\n",
    "# Predict using the adjusted SCALED test set\n",
    "predictions_log_scaled = model.predict(X_test_scaled_adjusted)\n",
    "end_time = time.time()\n",
    "\n",
    "# --- Inverse transform predictions ---\n",
    "# Step 1: Inverse scale using the output_scaler fitted on y_train_log [cite: 6]\n",
    "predictions_log = output_scaler.inverse_transform(predictions_log_scaled)\n",
    "# Step 2: Inverse the log transform using np.expm1 [cite: 6]\n",
    "predictions_unscaled_kp = np.expm1(predictions_log)\n",
    "\n",
    "# --- Calculate time metrics ---\n",
    "time_taken = end_time - start_time\n",
    "predictions_per_second = NUM_DEVICES / time_taken if time_taken > 0 else 0\n",
    "\n",
    "# --- Print timing results ---\n",
    "print(f\"\\nTime taken to predict {NUM_DEVICES} devices: {time_taken:.3f} seconds\")\n",
    "print(f\"Average predictions per second: {predictions_per_second:.2f}\")\n",
    "print(f\"Average time per prediction: {(time_taken / NUM_DEVICES) * 1000:.3f} milliseconds\" if NUM_DEVICES > 0 else \"N/A\")\n",
    "\n",
    "# --- Calculate accuracy metrics using ORIGINAL KP values ---\n",
    "# Compare predictions_unscaled_kp with y_test_original_kp_adjusted\n",
    "# Avoid division by zero using a small epsilon as in the PDF [cite: 6]\n",
    "epsilon = 1e-10\n",
    "relative_errors = np.abs((predictions_unscaled_kp - y_test_original_kp_adjusted) / (y_test_original_kp_adjusted + epsilon)) * 100\n",
    "\n",
    "mean_error_pct = np.mean(relative_errors)\n",
    "median_error_pct = np.median(relative_errors)\n",
    "std_error_pct = np.std(relative_errors)\n",
    "min_error_pct = np.min(relative_errors)\n",
    "max_error_pct = np.max(relative_errors)\n",
    "\n",
    "# Print accuracy results\n",
    "print(\"\\nAccuracy Statistics (KP Prediction Errors in % - Corrected):\")\n",
    "print(f\"Mean Error: {mean_error_pct:.2f}%\") # Matches PDF format [cite: 7]\n",
    "print(f\"Median Error: {median_error_pct:.2f}%\")\n",
    "print(f\"Standard Deviation: {std_error_pct:.2f}%\")\n",
    "print(f\"Min Error: {min_error_pct:.2f}%\")\n",
    "print(f\"Max Error: {max_error_pct:.2f}%\")\n",
    "\n",
    "# --- Calculate other metrics (Optional) ---\n",
    "r2 = r2_score(y_test_original_kp_adjusted, predictions_unscaled_kp)\n",
    "mse = mean_squared_error(y_test_original_kp_adjusted, predictions_unscaled_kp)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"\\nR² Score: {r2:.4f}\") # Matches PDF format [cite: 37]\n",
    "# Using scientific notation for MSE/RMSE as in PDF [cite: 37]\n",
    "print(f\"MSE: {mse:.4e}\")\n",
    "print(f\"RMSE: {rmse:.4e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOSFET_NN_mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
