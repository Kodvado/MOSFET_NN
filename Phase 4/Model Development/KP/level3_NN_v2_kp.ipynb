{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (X): (55000, 1685)\n",
      "Target shape (y): (55000, 1)\n",
      "Input dimension: 1685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,726,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,726,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,785</span> (9.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,785\u001b[0m (9.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,419,201</span> (9.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,419,201\u001b[0m (9.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> (14.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,584\u001b[0m (14.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 2.4772 - mae: 0.8145 - val_loss: 1.3930 - val_mae: 0.5826 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 1.1965 - mae: 0.4988 - val_loss: 0.7160 - val_mae: 0.4055 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.7323 - mae: 0.4520 - val_loss: 0.5472 - val_mae: 0.4143 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.5828 - mae: 0.4482 - val_loss: 0.4644 - val_mae: 0.3962 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.5161 - mae: 0.4317 - val_loss: 0.4357 - val_mae: 0.3926 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.5079 - mae: 0.4367 - val_loss: 0.4401 - val_mae: 0.3846 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4948 - mae: 0.4304 - val_loss: 0.4266 - val_mae: 0.3595 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4846 - mae: 0.4251 - val_loss: 0.3858 - val_mae: 0.3608 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4689 - mae: 0.4216 - val_loss: 0.3548 - val_mae: 0.3207 - learning_rate: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4852 - mae: 0.4285 - val_loss: 0.4028 - val_mae: 0.3564 - learning_rate: 0.0010\n",
      "Epoch 11/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4863 - mae: 0.4279 - val_loss: 0.3531 - val_mae: 0.3243 - learning_rate: 0.0010\n",
      "Epoch 12/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4551 - mae: 0.4148 - val_loss: 0.3593 - val_mae: 0.3268 - learning_rate: 0.0010\n",
      "Epoch 13/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4535 - mae: 0.4127 - val_loss: 0.3093 - val_mae: 0.3016 - learning_rate: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4335 - mae: 0.4063 - val_loss: 0.3223 - val_mae: 0.2939 - learning_rate: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4324 - mae: 0.4074 - val_loss: 0.3262 - val_mae: 0.3047 - learning_rate: 0.0010\n",
      "Epoch 16/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4268 - mae: 0.4025 - val_loss: 0.3133 - val_mae: 0.3111 - learning_rate: 0.0010\n",
      "Epoch 17/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4284 - mae: 0.4094 - val_loss: 0.3515 - val_mae: 0.3770 - learning_rate: 0.0010\n",
      "Epoch 18/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4200 - mae: 0.4034 - val_loss: 0.3340 - val_mae: 0.3468 - learning_rate: 0.0010\n",
      "Epoch 19/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4045 - mae: 0.3989 - val_loss: 0.3896 - val_mae: 0.3483 - learning_rate: 0.0010\n",
      "Epoch 20/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.4011 - mae: 0.3975 - val_loss: 0.3115 - val_mae: 0.3041 - learning_rate: 0.0010\n",
      "Epoch 21/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.3980 - mae: 0.3979 - val_loss: 0.2858 - val_mae: 0.3095 - learning_rate: 0.0010\n",
      "Epoch 22/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.3879 - mae: 0.3954 - val_loss: 0.2698 - val_mae: 0.2806 - learning_rate: 0.0010\n",
      "Epoch 23/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.3918 - mae: 0.3961 - val_loss: 0.3063 - val_mae: 0.3472 - learning_rate: 0.0010\n",
      "Epoch 24/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.3969 - mae: 0.4014 - val_loss: 0.2660 - val_mae: 0.2887 - learning_rate: 0.0010\n",
      "Epoch 25/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.3807 - mae: 0.3963 - val_loss: 0.2849 - val_mae: 0.3103 - learning_rate: 0.0010\n",
      "Epoch 26/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 0.3807 - mae: 0.3981 - val_loss: 0.2612 - val_mae: 0.2946 - learning_rate: 0.0010\n",
      "Epoch 27/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 0.3802 - mae: 0.3996 - val_loss: 0.2573 - val_mae: 0.2905 - learning_rate: 0.0010\n",
      "Epoch 28/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 0.3703 - mae: 0.3932 - val_loss: 0.2587 - val_mae: 0.2915 - learning_rate: 0.0010\n",
      "Epoch 29/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.3710 - mae: 0.3984 - val_loss: 0.3234 - val_mae: 0.3354 - learning_rate: 0.0010\n",
      "Epoch 30/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 0.3704 - mae: 0.3960 - val_loss: 0.2760 - val_mae: 0.3151 - learning_rate: 0.0010\n",
      "Epoch 31/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.3638 - mae: 0.3950 - val_loss: 0.2478 - val_mae: 0.2906 - learning_rate: 0.0010\n",
      "Epoch 32/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.3731 - mae: 0.4019 - val_loss: 0.2788 - val_mae: 0.3034 - learning_rate: 0.0010\n",
      "Epoch 33/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 0.3694 - mae: 0.3983 - val_loss: 0.2881 - val_mae: 0.3155 - learning_rate: 0.0010\n",
      "Epoch 34/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 0.3587 - mae: 0.3931 - val_loss: 0.2243 - val_mae: 0.2790 - learning_rate: 0.0010\n",
      "Epoch 35/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.3633 - mae: 0.3971 - val_loss: 0.2696 - val_mae: 0.3074 - learning_rate: 0.0010\n",
      "Epoch 36/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.3658 - mae: 0.3990 - val_loss: 0.2812 - val_mae: 0.3111 - learning_rate: 0.0010\n",
      "Epoch 37/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.3586 - mae: 0.3951 - val_loss: 0.2770 - val_mae: 0.3277 - learning_rate: 0.0010\n",
      "Epoch 38/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.3587 - mae: 0.3940 - val_loss: 0.3008 - val_mae: 0.3304 - learning_rate: 0.0010\n",
      "Epoch 39/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.3533 - mae: 0.3902 - val_loss: 0.2535 - val_mae: 0.2961 - learning_rate: 0.0010\n",
      "Epoch 40/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.3573 - mae: 0.3920 - val_loss: 0.2326 - val_mae: 0.2973 - learning_rate: 0.0010\n",
      "Epoch 41/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.3541 - mae: 0.3909 - val_loss: 0.2813 - val_mae: 0.3098 - learning_rate: 0.0010\n",
      "Epoch 42/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.3586 - mae: 0.3962 - val_loss: 0.2327 - val_mae: 0.2740 - learning_rate: 0.0010\n",
      "Epoch 43/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.3479 - mae: 0.3889 - val_loss: 0.3221 - val_mae: 0.3430 - learning_rate: 0.0010\n",
      "Epoch 44/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.3541 - mae: 0.3927 - val_loss: 0.2685 - val_mae: 0.3192 - learning_rate: 0.0010\n",
      "Epoch 45/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.3187 - mae: 0.3695 - val_loss: 0.1780 - val_mae: 0.2412 - learning_rate: 5.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2895 - mae: 0.3539 - val_loss: 0.2003 - val_mae: 0.2702 - learning_rate: 5.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2814 - mae: 0.3487 - val_loss: 0.2133 - val_mae: 0.2737 - learning_rate: 5.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2882 - mae: 0.3551 - val_loss: 0.1506 - val_mae: 0.2098 - learning_rate: 5.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2765 - mae: 0.3460 - val_loss: 0.1564 - val_mae: 0.2346 - learning_rate: 5.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2726 - mae: 0.3452 - val_loss: 0.1653 - val_mae: 0.2405 - learning_rate: 5.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2744 - mae: 0.3466 - val_loss: 0.1610 - val_mae: 0.2308 - learning_rate: 5.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2765 - mae: 0.3471 - val_loss: 0.1774 - val_mae: 0.2382 - learning_rate: 5.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2763 - mae: 0.3472 - val_loss: 0.2172 - val_mae: 0.2834 - learning_rate: 5.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.2808 - mae: 0.3523 - val_loss: 0.2229 - val_mae: 0.2889 - learning_rate: 5.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2679 - mae: 0.3417 - val_loss: 0.1460 - val_mae: 0.2258 - learning_rate: 5.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2778 - mae: 0.3498 - val_loss: 0.1662 - val_mae: 0.2316 - learning_rate: 5.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2752 - mae: 0.3488 - val_loss: 0.1693 - val_mae: 0.2561 - learning_rate: 5.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2676 - mae: 0.3426 - val_loss: 0.1717 - val_mae: 0.2617 - learning_rate: 5.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2715 - mae: 0.3473 - val_loss: 0.1650 - val_mae: 0.2320 - learning_rate: 5.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2684 - mae: 0.3425 - val_loss: 0.1826 - val_mae: 0.2604 - learning_rate: 5.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2670 - mae: 0.3420 - val_loss: 0.1581 - val_mae: 0.2401 - learning_rate: 5.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2660 - mae: 0.3414 - val_loss: 0.1818 - val_mae: 0.2524 - learning_rate: 5.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2695 - mae: 0.3451 - val_loss: 0.1865 - val_mae: 0.2775 - learning_rate: 5.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2655 - mae: 0.3405 - val_loss: 0.1815 - val_mae: 0.2555 - learning_rate: 5.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2652 - mae: 0.3418 - val_loss: 0.2268 - val_mae: 0.2990 - learning_rate: 5.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2439 - mae: 0.3244 - val_loss: 0.1458 - val_mae: 0.2295 - learning_rate: 2.5000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2272 - mae: 0.3132 - val_loss: 0.1326 - val_mae: 0.2246 - learning_rate: 2.5000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2276 - mae: 0.3158 - val_loss: 0.1414 - val_mae: 0.2322 - learning_rate: 2.5000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2211 - mae: 0.3107 - val_loss: 0.1427 - val_mae: 0.2269 - learning_rate: 2.5000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2272 - mae: 0.3160 - val_loss: 0.1789 - val_mae: 0.2566 - learning_rate: 2.5000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2225 - mae: 0.3114 - val_loss: 0.1497 - val_mae: 0.2399 - learning_rate: 2.5000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2232 - mae: 0.3122 - val_loss: 0.1333 - val_mae: 0.2189 - learning_rate: 2.5000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2164 - mae: 0.3081 - val_loss: 0.1492 - val_mae: 0.2477 - learning_rate: 2.5000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2189 - mae: 0.3106 - val_loss: 0.1469 - val_mae: 0.2268 - learning_rate: 2.5000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2117 - mae: 0.3052 - val_loss: 0.1302 - val_mae: 0.2096 - learning_rate: 2.5000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2186 - mae: 0.3103 - val_loss: 0.1321 - val_mae: 0.2252 - learning_rate: 2.5000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2146 - mae: 0.3070 - val_loss: 0.1103 - val_mae: 0.1964 - learning_rate: 2.5000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2149 - mae: 0.3082 - val_loss: 0.1430 - val_mae: 0.2249 - learning_rate: 2.5000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2157 - mae: 0.3094 - val_loss: 0.1297 - val_mae: 0.2211 - learning_rate: 2.5000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.2167 - mae: 0.3086 - val_loss: 0.1324 - val_mae: 0.2164 - learning_rate: 2.5000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.2148 - mae: 0.3072 - val_loss: 0.1253 - val_mae: 0.2099 - learning_rate: 2.5000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2193 - mae: 0.3109 - val_loss: 0.1229 - val_mae: 0.2136 - learning_rate: 2.5000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2152 - mae: 0.3073 - val_loss: 0.1323 - val_mae: 0.2181 - learning_rate: 2.5000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2142 - mae: 0.3074 - val_loss: 0.1302 - val_mae: 0.2174 - learning_rate: 2.5000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2137 - mae: 0.3059 - val_loss: 0.1548 - val_mae: 0.2379 - learning_rate: 2.5000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2159 - mae: 0.3078 - val_loss: 0.1509 - val_mae: 0.2347 - learning_rate: 2.5000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.2182 - mae: 0.3098 - val_loss: 0.1482 - val_mae: 0.2327 - learning_rate: 2.5000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1942 - mae: 0.2892 - val_loss: 0.1100 - val_mae: 0.1917 - learning_rate: 1.2500e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1877 - mae: 0.2841 - val_loss: 0.1070 - val_mae: 0.1967 - learning_rate: 1.2500e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1849 - mae: 0.2820 - val_loss: 0.1233 - val_mae: 0.2067 - learning_rate: 1.2500e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1828 - mae: 0.2805 - val_loss: 0.1142 - val_mae: 0.1995 - learning_rate: 1.2500e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1803 - mae: 0.2781 - val_loss: 0.1076 - val_mae: 0.1918 - learning_rate: 1.2500e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1812 - mae: 0.2802 - val_loss: 0.1009 - val_mae: 0.1858 - learning_rate: 1.2500e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1811 - mae: 0.2788 - val_loss: 0.1076 - val_mae: 0.1924 - learning_rate: 1.2500e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1802 - mae: 0.2789 - val_loss: 0.1165 - val_mae: 0.2064 - learning_rate: 1.2500e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1809 - mae: 0.2799 - val_loss: 0.1061 - val_mae: 0.1910 - learning_rate: 1.2500e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1769 - mae: 0.2763 - val_loss: 0.1136 - val_mae: 0.1960 - learning_rate: 1.2500e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1807 - mae: 0.2787 - val_loss: 0.0996 - val_mae: 0.1898 - learning_rate: 1.2500e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1720 - mae: 0.2719 - val_loss: 0.1045 - val_mae: 0.1886 - learning_rate: 1.2500e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1741 - mae: 0.2741 - val_loss: 0.0959 - val_mae: 0.1844 - learning_rate: 1.2500e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1760 - mae: 0.2756 - val_loss: 0.1000 - val_mae: 0.1936 - learning_rate: 1.2500e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1728 - mae: 0.2743 - val_loss: 0.1122 - val_mae: 0.1957 - learning_rate: 1.2500e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1753 - mae: 0.2741 - val_loss: 0.1057 - val_mae: 0.1879 - learning_rate: 1.2500e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1753 - mae: 0.2762 - val_loss: 0.1151 - val_mae: 0.2172 - learning_rate: 1.2500e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1757 - mae: 0.2767 - val_loss: 0.1095 - val_mae: 0.1996 - learning_rate: 1.2500e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1743 - mae: 0.2766 - val_loss: 0.0942 - val_mae: 0.1857 - learning_rate: 1.2500e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1730 - mae: 0.2745 - val_loss: 0.1035 - val_mae: 0.1885 - learning_rate: 1.2500e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1733 - mae: 0.2753 - val_loss: 0.1122 - val_mae: 0.2071 - learning_rate: 1.2500e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1737 - mae: 0.2742 - val_loss: 0.0950 - val_mae: 0.1800 - learning_rate: 1.2500e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1749 - mae: 0.2745 - val_loss: 0.0861 - val_mae: 0.1637 - learning_rate: 1.2500e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1684 - mae: 0.2696 - val_loss: 0.1109 - val_mae: 0.2064 - learning_rate: 1.2500e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1698 - mae: 0.2720 - val_loss: 0.1025 - val_mae: 0.1840 - learning_rate: 1.2500e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1709 - mae: 0.2729 - val_loss: 0.1112 - val_mae: 0.1965 - learning_rate: 1.2500e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1694 - mae: 0.2722 - val_loss: 0.0997 - val_mae: 0.1825 - learning_rate: 1.2500e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1717 - mae: 0.2736 - val_loss: 0.1115 - val_mae: 0.2061 - learning_rate: 1.2500e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1734 - mae: 0.2754 - val_loss: 0.1150 - val_mae: 0.2019 - learning_rate: 1.2500e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1749 - mae: 0.2760 - val_loss: 0.1110 - val_mae: 0.2045 - learning_rate: 1.2500e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1668 - mae: 0.2691 - val_loss: 0.1365 - val_mae: 0.2191 - learning_rate: 1.2500e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1698 - mae: 0.2718 - val_loss: 0.1054 - val_mae: 0.1927 - learning_rate: 1.2500e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1682 - mae: 0.2711 - val_loss: 0.1055 - val_mae: 0.1923 - learning_rate: 1.2500e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1593 - mae: 0.2633 - val_loss: 0.0988 - val_mae: 0.1849 - learning_rate: 6.2500e-05\n",
      "Epoch 122/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1567 - mae: 0.2600 - val_loss: 0.0864 - val_mae: 0.1685 - learning_rate: 6.2500e-05\n",
      "Epoch 123/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1520 - mae: 0.2562 - val_loss: 0.0845 - val_mae: 0.1620 - learning_rate: 6.2500e-05\n",
      "Epoch 124/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1520 - mae: 0.2557 - val_loss: 0.0948 - val_mae: 0.1755 - learning_rate: 6.2500e-05\n",
      "Epoch 125/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1520 - mae: 0.2544 - val_loss: 0.0825 - val_mae: 0.1597 - learning_rate: 6.2500e-05\n",
      "Epoch 126/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1517 - mae: 0.2553 - val_loss: 0.0886 - val_mae: 0.1701 - learning_rate: 6.2500e-05\n",
      "Epoch 127/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1473 - mae: 0.2504 - val_loss: 0.0844 - val_mae: 0.1615 - learning_rate: 6.2500e-05\n",
      "Epoch 128/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1475 - mae: 0.2507 - val_loss: 0.0985 - val_mae: 0.1761 - learning_rate: 6.2500e-05\n",
      "Epoch 129/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1495 - mae: 0.2529 - val_loss: 0.0787 - val_mae: 0.1592 - learning_rate: 6.2500e-05\n",
      "Epoch 130/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1466 - mae: 0.2511 - val_loss: 0.0940 - val_mae: 0.1781 - learning_rate: 6.2500e-05\n",
      "Epoch 131/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1461 - mae: 0.2491 - val_loss: 0.0941 - val_mae: 0.1753 - learning_rate: 6.2500e-05\n",
      "Epoch 132/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1479 - mae: 0.2496 - val_loss: 0.0989 - val_mae: 0.1828 - learning_rate: 6.2500e-05\n",
      "Epoch 133/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1448 - mae: 0.2486 - val_loss: 0.0804 - val_mae: 0.1578 - learning_rate: 6.2500e-05\n",
      "Epoch 134/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1468 - mae: 0.2486 - val_loss: 0.0901 - val_mae: 0.1710 - learning_rate: 6.2500e-05\n",
      "Epoch 135/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1455 - mae: 0.2478 - val_loss: 0.0957 - val_mae: 0.1788 - learning_rate: 6.2500e-05\n",
      "Epoch 136/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1432 - mae: 0.2475 - val_loss: 0.0856 - val_mae: 0.1667 - learning_rate: 6.2500e-05\n",
      "Epoch 137/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1410 - mae: 0.2451 - val_loss: 0.0864 - val_mae: 0.1700 - learning_rate: 6.2500e-05\n",
      "Epoch 138/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1413 - mae: 0.2445 - val_loss: 0.0800 - val_mae: 0.1557 - learning_rate: 6.2500e-05\n",
      "Epoch 139/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1447 - mae: 0.2476 - val_loss: 0.0759 - val_mae: 0.1553 - learning_rate: 6.2500e-05\n",
      "Epoch 140/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1420 - mae: 0.2467 - val_loss: 0.0899 - val_mae: 0.1748 - learning_rate: 6.2500e-05\n",
      "Epoch 141/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1437 - mae: 0.2469 - val_loss: 0.0824 - val_mae: 0.1628 - learning_rate: 6.2500e-05\n",
      "Epoch 142/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1422 - mae: 0.2461 - val_loss: 0.0810 - val_mae: 0.1616 - learning_rate: 6.2500e-05\n",
      "Epoch 143/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1434 - mae: 0.2459 - val_loss: 0.0802 - val_mae: 0.1654 - learning_rate: 6.2500e-05\n",
      "Epoch 144/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1407 - mae: 0.2447 - val_loss: 0.0790 - val_mae: 0.1593 - learning_rate: 6.2500e-05\n",
      "Epoch 145/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1406 - mae: 0.2450 - val_loss: 0.0839 - val_mae: 0.1665 - learning_rate: 6.2500e-05\n",
      "Epoch 146/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1392 - mae: 0.2440 - val_loss: 0.0817 - val_mae: 0.1610 - learning_rate: 6.2500e-05\n",
      "Epoch 147/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1391 - mae: 0.2444 - val_loss: 0.0869 - val_mae: 0.1641 - learning_rate: 6.2500e-05\n",
      "Epoch 148/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1407 - mae: 0.2443 - val_loss: 0.0795 - val_mae: 0.1564 - learning_rate: 6.2500e-05\n",
      "Epoch 149/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1385 - mae: 0.2427 - val_loss: 0.0789 - val_mae: 0.1565 - learning_rate: 6.2500e-05\n",
      "Epoch 150/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1345 - mae: 0.2392 - val_loss: 0.0728 - val_mae: 0.1500 - learning_rate: 3.1250e-05\n",
      "Epoch 151/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1294 - mae: 0.2330 - val_loss: 0.0761 - val_mae: 0.1508 - learning_rate: 3.1250e-05\n",
      "Epoch 152/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1309 - mae: 0.2344 - val_loss: 0.0781 - val_mae: 0.1556 - learning_rate: 3.1250e-05\n",
      "Epoch 153/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1266 - mae: 0.2321 - val_loss: 0.0780 - val_mae: 0.1586 - learning_rate: 3.1250e-05\n",
      "Epoch 154/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1271 - mae: 0.2307 - val_loss: 0.0952 - val_mae: 0.1762 - learning_rate: 3.1250e-05\n",
      "Epoch 155/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1282 - mae: 0.2329 - val_loss: 0.0698 - val_mae: 0.1462 - learning_rate: 3.1250e-05\n",
      "Epoch 156/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1245 - mae: 0.2285 - val_loss: 0.0719 - val_mae: 0.1475 - learning_rate: 3.1250e-05\n",
      "Epoch 157/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1247 - mae: 0.2285 - val_loss: 0.0757 - val_mae: 0.1541 - learning_rate: 3.1250e-05\n",
      "Epoch 158/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1249 - mae: 0.2284 - val_loss: 0.0750 - val_mae: 0.1505 - learning_rate: 3.1250e-05\n",
      "Epoch 159/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1264 - mae: 0.2299 - val_loss: 0.0760 - val_mae: 0.1533 - learning_rate: 3.1250e-05\n",
      "Epoch 160/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1257 - mae: 0.2303 - val_loss: 0.0704 - val_mae: 0.1431 - learning_rate: 3.1250e-05\n",
      "Epoch 161/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1240 - mae: 0.2287 - val_loss: 0.0774 - val_mae: 0.1549 - learning_rate: 3.1250e-05\n",
      "Epoch 162/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1242 - mae: 0.2297 - val_loss: 0.0735 - val_mae: 0.1476 - learning_rate: 3.1250e-05\n",
      "Epoch 163/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1253 - mae: 0.2300 - val_loss: 0.0783 - val_mae: 0.1557 - learning_rate: 3.1250e-05\n",
      "Epoch 164/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1251 - mae: 0.2295 - val_loss: 0.0820 - val_mae: 0.1591 - learning_rate: 3.1250e-05\n",
      "Epoch 165/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1232 - mae: 0.2275 - val_loss: 0.0707 - val_mae: 0.1424 - learning_rate: 3.1250e-05\n",
      "Epoch 166/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1202 - mae: 0.2243 - val_loss: 0.0717 - val_mae: 0.1448 - learning_rate: 1.5625e-05\n",
      "Epoch 167/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1202 - mae: 0.2245 - val_loss: 0.0698 - val_mae: 0.1429 - learning_rate: 1.5625e-05\n",
      "Epoch 168/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1174 - mae: 0.2207 - val_loss: 0.0686 - val_mae: 0.1411 - learning_rate: 1.5625e-05\n",
      "Epoch 169/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.1181 - mae: 0.2212 - val_loss: 0.0691 - val_mae: 0.1437 - learning_rate: 1.5625e-05\n",
      "Epoch 170/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1164 - mae: 0.2189 - val_loss: 0.0667 - val_mae: 0.1392 - learning_rate: 1.5625e-05\n",
      "Epoch 171/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1163 - mae: 0.2188 - val_loss: 0.0721 - val_mae: 0.1460 - learning_rate: 1.5625e-05\n",
      "Epoch 172/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1169 - mae: 0.2189 - val_loss: 0.0675 - val_mae: 0.1399 - learning_rate: 1.5625e-05\n",
      "Epoch 173/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1154 - mae: 0.2192 - val_loss: 0.0729 - val_mae: 0.1463 - learning_rate: 1.5625e-05\n",
      "Epoch 174/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1133 - mae: 0.2169 - val_loss: 0.0649 - val_mae: 0.1362 - learning_rate: 1.5625e-05\n",
      "Epoch 175/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1168 - mae: 0.2200 - val_loss: 0.0686 - val_mae: 0.1403 - learning_rate: 1.5625e-05\n",
      "Epoch 176/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1118 - mae: 0.2156 - val_loss: 0.0700 - val_mae: 0.1465 - learning_rate: 1.5625e-05\n",
      "Epoch 177/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1165 - mae: 0.2203 - val_loss: 0.0658 - val_mae: 0.1353 - learning_rate: 1.5625e-05\n",
      "Epoch 178/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1140 - mae: 0.2184 - val_loss: 0.0664 - val_mae: 0.1387 - learning_rate: 1.5625e-05\n",
      "Epoch 179/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1135 - mae: 0.2165 - val_loss: 0.0753 - val_mae: 0.1501 - learning_rate: 1.5625e-05\n",
      "Epoch 180/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1115 - mae: 0.2156 - val_loss: 0.0629 - val_mae: 0.1320 - learning_rate: 1.5625e-05\n",
      "Epoch 181/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1136 - mae: 0.2173 - val_loss: 0.0734 - val_mae: 0.1472 - learning_rate: 1.5625e-05\n",
      "Epoch 182/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1136 - mae: 0.2169 - val_loss: 0.0712 - val_mae: 0.1451 - learning_rate: 1.5625e-05\n",
      "Epoch 183/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1134 - mae: 0.2165 - val_loss: 0.0659 - val_mae: 0.1371 - learning_rate: 1.5625e-05\n",
      "Epoch 184/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1125 - mae: 0.2150 - val_loss: 0.0673 - val_mae: 0.1396 - learning_rate: 1.5625e-05\n",
      "Epoch 185/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1114 - mae: 0.2134 - val_loss: 0.0639 - val_mae: 0.1338 - learning_rate: 1.5625e-05\n",
      "Epoch 186/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1091 - mae: 0.2126 - val_loss: 0.0635 - val_mae: 0.1340 - learning_rate: 1.5625e-05\n",
      "Epoch 187/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1121 - mae: 0.2152 - val_loss: 0.0679 - val_mae: 0.1395 - learning_rate: 1.5625e-05\n",
      "Epoch 188/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1118 - mae: 0.2154 - val_loss: 0.0701 - val_mae: 0.1448 - learning_rate: 1.5625e-05\n",
      "Epoch 189/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1102 - mae: 0.2139 - val_loss: 0.0645 - val_mae: 0.1357 - learning_rate: 1.5625e-05\n",
      "Epoch 190/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1096 - mae: 0.2124 - val_loss: 0.0665 - val_mae: 0.1389 - learning_rate: 1.5625e-05\n",
      "Epoch 191/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1082 - mae: 0.2117 - val_loss: 0.0618 - val_mae: 0.1291 - learning_rate: 7.8125e-06\n",
      "Epoch 192/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1081 - mae: 0.2115 - val_loss: 0.0601 - val_mae: 0.1282 - learning_rate: 7.8125e-06\n",
      "Epoch 193/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1086 - mae: 0.2108 - val_loss: 0.0596 - val_mae: 0.1262 - learning_rate: 7.8125e-06\n",
      "Epoch 194/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1084 - mae: 0.2115 - val_loss: 0.0610 - val_mae: 0.1279 - learning_rate: 7.8125e-06\n",
      "Epoch 195/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1082 - mae: 0.2098 - val_loss: 0.0665 - val_mae: 0.1370 - learning_rate: 7.8125e-06\n",
      "Epoch 196/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1088 - mae: 0.2119 - val_loss: 0.0630 - val_mae: 0.1317 - learning_rate: 7.8125e-06\n",
      "Epoch 197/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1068 - mae: 0.2098 - val_loss: 0.0655 - val_mae: 0.1372 - learning_rate: 7.8125e-06\n",
      "Epoch 198/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1065 - mae: 0.2085 - val_loss: 0.0599 - val_mae: 0.1288 - learning_rate: 7.8125e-06\n",
      "Epoch 199/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1089 - mae: 0.2115 - val_loss: 0.0606 - val_mae: 0.1284 - learning_rate: 7.8125e-06\n",
      "Epoch 200/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1053 - mae: 0.2080 - val_loss: 0.0598 - val_mae: 0.1246 - learning_rate: 7.8125e-06\n",
      "Epoch 201/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1082 - mae: 0.2102 - val_loss: 0.0582 - val_mae: 0.1240 - learning_rate: 7.8125e-06\n",
      "Epoch 202/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1059 - mae: 0.2085 - val_loss: 0.0631 - val_mae: 0.1325 - learning_rate: 7.8125e-06\n",
      "Epoch 203/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1053 - mae: 0.2083 - val_loss: 0.0642 - val_mae: 0.1354 - learning_rate: 7.8125e-06\n",
      "Epoch 204/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1075 - mae: 0.2104 - val_loss: 0.0623 - val_mae: 0.1299 - learning_rate: 7.8125e-06\n",
      "Epoch 205/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1047 - mae: 0.2071 - val_loss: 0.0612 - val_mae: 0.1265 - learning_rate: 7.8125e-06\n",
      "Epoch 206/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1063 - mae: 0.2086 - val_loss: 0.0617 - val_mae: 0.1284 - learning_rate: 7.8125e-06\n",
      "Epoch 207/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1067 - mae: 0.2092 - val_loss: 0.0602 - val_mae: 0.1270 - learning_rate: 7.8125e-06\n",
      "Epoch 208/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1057 - mae: 0.2084 - val_loss: 0.0614 - val_mae: 0.1290 - learning_rate: 7.8125e-06\n",
      "Epoch 209/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1074 - mae: 0.2089 - val_loss: 0.0578 - val_mae: 0.1226 - learning_rate: 7.8125e-06\n",
      "Epoch 210/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1065 - mae: 0.2086 - val_loss: 0.0594 - val_mae: 0.1249 - learning_rate: 7.8125e-06\n",
      "Epoch 211/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1042 - mae: 0.2069 - val_loss: 0.0629 - val_mae: 0.1309 - learning_rate: 7.8125e-06\n",
      "Epoch 212/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1072 - mae: 0.2097 - val_loss: 0.0605 - val_mae: 0.1292 - learning_rate: 7.8125e-06\n",
      "Epoch 213/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.1029 - mae: 0.2055 - val_loss: 0.0580 - val_mae: 0.1215 - learning_rate: 7.8125e-06\n",
      "Epoch 214/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1030 - mae: 0.2059 - val_loss: 0.0593 - val_mae: 0.1265 - learning_rate: 7.8125e-06\n",
      "Epoch 215/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1049 - mae: 0.2071 - val_loss: 0.0598 - val_mae: 0.1263 - learning_rate: 7.8125e-06\n",
      "Epoch 216/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.1040 - mae: 0.2066 - val_loss: 0.0617 - val_mae: 0.1290 - learning_rate: 7.8125e-06\n",
      "Epoch 217/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 0.1050 - mae: 0.2075 - val_loss: 0.0612 - val_mae: 0.1269 - learning_rate: 7.8125e-06\n",
      "Epoch 218/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.1045 - mae: 0.2074 - val_loss: 0.0591 - val_mae: 0.1269 - learning_rate: 7.8125e-06\n",
      "Epoch 219/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.1036 - mae: 0.2057 - val_loss: 0.0614 - val_mae: 0.1280 - learning_rate: 7.8125e-06\n",
      "Epoch 220/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 0.1021 - mae: 0.2035 - val_loss: 0.0584 - val_mae: 0.1207 - learning_rate: 3.9063e-06\n",
      "Epoch 221/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1024 - mae: 0.2040 - val_loss: 0.0568 - val_mae: 0.1204 - learning_rate: 3.9063e-06\n",
      "Epoch 222/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1016 - mae: 0.2039 - val_loss: 0.0586 - val_mae: 0.1231 - learning_rate: 3.9063e-06\n",
      "Epoch 223/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1022 - mae: 0.2040 - val_loss: 0.0584 - val_mae: 0.1231 - learning_rate: 3.9063e-06\n",
      "Epoch 224/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1021 - mae: 0.2040 - val_loss: 0.0605 - val_mae: 0.1269 - learning_rate: 3.9063e-06\n",
      "Epoch 225/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1014 - mae: 0.2022 - val_loss: 0.0605 - val_mae: 0.1273 - learning_rate: 3.9063e-06\n",
      "Epoch 226/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1027 - mae: 0.2048 - val_loss: 0.0573 - val_mae: 0.1214 - learning_rate: 3.9063e-06\n",
      "Epoch 227/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 0.1028 - mae: 0.2045 - val_loss: 0.0582 - val_mae: 0.1236 - learning_rate: 3.9063e-06\n",
      "Epoch 228/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1021 - mae: 0.2033 - val_loss: 0.0576 - val_mae: 0.1226 - learning_rate: 3.9063e-06\n",
      "Epoch 229/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1013 - mae: 0.2022 - val_loss: 0.0598 - val_mae: 0.1256 - learning_rate: 3.9063e-06\n",
      "Epoch 230/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1019 - mae: 0.2038 - val_loss: 0.0589 - val_mae: 0.1231 - learning_rate: 3.9063e-06\n",
      "Epoch 231/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1017 - mae: 0.2027 - val_loss: 0.0595 - val_mae: 0.1258 - learning_rate: 3.9063e-06\n",
      "Epoch 232/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1020 - mae: 0.2029 - val_loss: 0.0578 - val_mae: 0.1217 - learning_rate: 1.9531e-06\n",
      "Epoch 233/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1006 - mae: 0.2016 - val_loss: 0.0575 - val_mae: 0.1213 - learning_rate: 1.9531e-06\n",
      "Epoch 234/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1024 - mae: 0.2036 - val_loss: 0.0572 - val_mae: 0.1216 - learning_rate: 1.9531e-06\n",
      "Epoch 235/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - loss: 0.1018 - mae: 0.2035 - val_loss: 0.0554 - val_mae: 0.1176 - learning_rate: 1.9531e-06\n",
      "Epoch 236/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1004 - mae: 0.2020 - val_loss: 0.0554 - val_mae: 0.1175 - learning_rate: 1.9531e-06\n",
      "Epoch 237/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1011 - mae: 0.2028 - val_loss: 0.0572 - val_mae: 0.1224 - learning_rate: 1.9531e-06\n",
      "Epoch 238/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0996 - mae: 0.2003 - val_loss: 0.0562 - val_mae: 0.1201 - learning_rate: 1.9531e-06\n",
      "Epoch 239/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0994 - mae: 0.2009 - val_loss: 0.0568 - val_mae: 0.1211 - learning_rate: 1.9531e-06\n",
      "Epoch 240/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1003 - mae: 0.2022 - val_loss: 0.0561 - val_mae: 0.1196 - learning_rate: 1.9531e-06\n",
      "Epoch 241/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0989 - mae: 0.2002 - val_loss: 0.0567 - val_mae: 0.1209 - learning_rate: 1.9531e-06\n",
      "Epoch 242/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1002 - mae: 0.2023 - val_loss: 0.0553 - val_mae: 0.1185 - learning_rate: 1.9531e-06\n",
      "Epoch 243/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1002 - mae: 0.2017 - val_loss: 0.0559 - val_mae: 0.1192 - learning_rate: 1.9531e-06\n",
      "Epoch 244/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0996 - mae: 0.2010 - val_loss: 0.0569 - val_mae: 0.1208 - learning_rate: 1.9531e-06\n",
      "Epoch 245/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1002 - mae: 0.2028 - val_loss: 0.0570 - val_mae: 0.1206 - learning_rate: 1.9531e-06\n",
      "Epoch 246/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1013 - mae: 0.2027 - val_loss: 0.0555 - val_mae: 0.1185 - learning_rate: 1.9531e-06\n",
      "Epoch 247/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0999 - mae: 0.2004 - val_loss: 0.0562 - val_mae: 0.1194 - learning_rate: 1.9531e-06\n",
      "Epoch 248/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1006 - mae: 0.2032 - val_loss: 0.0566 - val_mae: 0.1204 - learning_rate: 1.9531e-06\n",
      "Epoch 249/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.0979 - mae: 0.1994 - val_loss: 0.0553 - val_mae: 0.1184 - learning_rate: 1.9531e-06\n",
      "Epoch 250/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0993 - mae: 0.1996 - val_loss: 0.0569 - val_mae: 0.1214 - learning_rate: 1.9531e-06\n",
      "Epoch 251/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0999 - mae: 0.2017 - val_loss: 0.0557 - val_mae: 0.1187 - learning_rate: 1.9531e-06\n",
      "Epoch 252/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0998 - mae: 0.2016 - val_loss: 0.0544 - val_mae: 0.1169 - learning_rate: 1.9531e-06\n",
      "Epoch 253/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0991 - mae: 0.2003 - val_loss: 0.0579 - val_mae: 0.1239 - learning_rate: 1.9531e-06\n",
      "Epoch 254/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0976 - mae: 0.1988 - val_loss: 0.0544 - val_mae: 0.1166 - learning_rate: 1.9531e-06\n",
      "Epoch 255/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0993 - mae: 0.1996 - val_loss: 0.0561 - val_mae: 0.1206 - learning_rate: 1.9531e-06\n",
      "Epoch 256/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0999 - mae: 0.2005 - val_loss: 0.0557 - val_mae: 0.1188 - learning_rate: 1.9531e-06\n",
      "Epoch 257/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0980 - mae: 0.2007 - val_loss: 0.0550 - val_mae: 0.1174 - learning_rate: 1.9531e-06\n",
      "Epoch 258/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0991 - mae: 0.2007 - val_loss: 0.0557 - val_mae: 0.1189 - learning_rate: 1.9531e-06\n",
      "Epoch 259/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.1017 - mae: 0.2034 - val_loss: 0.0559 - val_mae: 0.1199 - learning_rate: 1.9531e-06\n",
      "Epoch 260/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1006 - mae: 0.2018 - val_loss: 0.0579 - val_mae: 0.1225 - learning_rate: 1.9531e-06\n",
      "Epoch 261/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0984 - mae: 0.2004 - val_loss: 0.0553 - val_mae: 0.1181 - learning_rate: 1.9531e-06\n",
      "Epoch 262/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0984 - mae: 0.2000 - val_loss: 0.0553 - val_mae: 0.1192 - learning_rate: 1.9531e-06\n",
      "Epoch 263/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0993 - mae: 0.2004 - val_loss: 0.0559 - val_mae: 0.1192 - learning_rate: 1.0000e-06\n",
      "Epoch 264/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.0997 - mae: 0.2012 - val_loss: 0.0552 - val_mae: 0.1180 - learning_rate: 1.0000e-06\n",
      "Epoch 265/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.0969 - mae: 0.1980 - val_loss: 0.0549 - val_mae: 0.1179 - learning_rate: 1.0000e-06\n",
      "Epoch 266/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0985 - mae: 0.1993 - val_loss: 0.0560 - val_mae: 0.1194 - learning_rate: 1.0000e-06\n",
      "Epoch 267/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0978 - mae: 0.1993 - val_loss: 0.0556 - val_mae: 0.1176 - learning_rate: 1.0000e-06\n",
      "Epoch 268/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0977 - mae: 0.1984 - val_loss: 0.0556 - val_mae: 0.1181 - learning_rate: 1.0000e-06\n",
      "Epoch 269/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0993 - mae: 0.2002 - val_loss: 0.0553 - val_mae: 0.1185 - learning_rate: 1.0000e-06\n",
      "Epoch 270/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0973 - mae: 0.1975 - val_loss: 0.0562 - val_mae: 0.1197 - learning_rate: 1.0000e-06\n",
      "Epoch 271/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0979 - mae: 0.1980 - val_loss: 0.0552 - val_mae: 0.1171 - learning_rate: 1.0000e-06\n",
      "Epoch 272/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0990 - mae: 0.1997 - val_loss: 0.0563 - val_mae: 0.1193 - learning_rate: 1.0000e-06\n",
      "Epoch 273/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0994 - mae: 0.2017 - val_loss: 0.0549 - val_mae: 0.1167 - learning_rate: 1.0000e-06\n",
      "Epoch 274/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0986 - mae: 0.1992 - val_loss: 0.0556 - val_mae: 0.1181 - learning_rate: 1.0000e-06\n",
      "Epoch 275/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0988 - mae: 0.1993 - val_loss: 0.0548 - val_mae: 0.1164 - learning_rate: 1.0000e-06\n",
      "Epoch 276/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0986 - mae: 0.1994 - val_loss: 0.0540 - val_mae: 0.1155 - learning_rate: 1.0000e-06\n",
      "Epoch 277/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0977 - mae: 0.1992 - val_loss: 0.0547 - val_mae: 0.1166 - learning_rate: 1.0000e-06\n",
      "Epoch 278/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0965 - mae: 0.1973 - val_loss: 0.0558 - val_mae: 0.1192 - learning_rate: 1.0000e-06\n",
      "Epoch 279/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0984 - mae: 0.1999 - val_loss: 0.0555 - val_mae: 0.1174 - learning_rate: 1.0000e-06\n",
      "Epoch 280/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1009 - mae: 0.2014 - val_loss: 0.0555 - val_mae: 0.1194 - learning_rate: 1.0000e-06\n",
      "Epoch 281/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.1001 - mae: 0.2018 - val_loss: 0.0550 - val_mae: 0.1180 - learning_rate: 1.0000e-06\n",
      "Epoch 282/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0991 - mae: 0.2008 - val_loss: 0.0545 - val_mae: 0.1176 - learning_rate: 1.0000e-06\n",
      "Epoch 283/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0986 - mae: 0.1998 - val_loss: 0.0549 - val_mae: 0.1167 - learning_rate: 1.0000e-06\n",
      "Epoch 284/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0981 - mae: 0.1993 - val_loss: 0.0545 - val_mae: 0.1163 - learning_rate: 1.0000e-06\n",
      "Epoch 285/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0983 - mae: 0.1989 - val_loss: 0.0549 - val_mae: 0.1173 - learning_rate: 1.0000e-06\n",
      "Epoch 286/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0971 - mae: 0.1990 - val_loss: 0.0550 - val_mae: 0.1174 - learning_rate: 1.0000e-06\n",
      "Epoch 287/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0993 - mae: 0.2003 - val_loss: 0.0545 - val_mae: 0.1165 - learning_rate: 1.0000e-06\n",
      "Epoch 288/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0979 - mae: 0.1991 - val_loss: 0.0540 - val_mae: 0.1149 - learning_rate: 1.0000e-06\n",
      "Epoch 289/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0990 - mae: 0.2004 - val_loss: 0.0558 - val_mae: 0.1193 - learning_rate: 1.0000e-06\n",
      "Epoch 290/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0976 - mae: 0.1995 - val_loss: 0.0556 - val_mae: 0.1195 - learning_rate: 1.0000e-06\n",
      "Epoch 291/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0993 - mae: 0.2012 - val_loss: 0.0545 - val_mae: 0.1171 - learning_rate: 1.0000e-06\n",
      "Epoch 292/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0989 - mae: 0.2006 - val_loss: 0.0549 - val_mae: 0.1173 - learning_rate: 1.0000e-06\n",
      "Epoch 293/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0968 - mae: 0.1971 - val_loss: 0.0554 - val_mae: 0.1174 - learning_rate: 1.0000e-06\n",
      "Epoch 294/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0976 - mae: 0.1986 - val_loss: 0.0564 - val_mae: 0.1203 - learning_rate: 1.0000e-06\n",
      "Epoch 295/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0986 - mae: 0.1980 - val_loss: 0.0544 - val_mae: 0.1162 - learning_rate: 1.0000e-06\n",
      "Epoch 296/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0970 - mae: 0.1981 - val_loss: 0.0553 - val_mae: 0.1186 - learning_rate: 1.0000e-06\n",
      "Epoch 297/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0987 - mae: 0.2005 - val_loss: 0.0564 - val_mae: 0.1202 - learning_rate: 1.0000e-06\n",
      "Epoch 298/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0978 - mae: 0.1983 - val_loss: 0.0539 - val_mae: 0.1148 - learning_rate: 1.0000e-06\n",
      "Epoch 299/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0977 - mae: 0.1994 - val_loss: 0.0539 - val_mae: 0.1159 - learning_rate: 1.0000e-06\n",
      "Epoch 300/300\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 0.0987 - mae: 0.2006 - val_loss: 0.0547 - val_mae: 0.1175 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Overall Percentage Errors:\n",
      "KP: 147.62%\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Data Preparation with W and L as Inputs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load MOSFET parameter and measurement data\n",
    "params_df = pd.read_csv('mosfet_params_level3_v11.csv')\n",
    "measurements_df = pd.read_csv('measurements_level3_v11.csv')\n",
    "\n",
    "# Group measurements and prepare input features\n",
    "X_list = []\n",
    "mosfet_ids = []\n",
    "\n",
    "grouped = measurements_df.groupby('MOSFET_ID')\n",
    "for mosfet_id, group in grouped:\n",
    "    group_sorted = group.sort_values('meas_index')\n",
    "    if len(group_sorted) == 561:\n",
    "        measurement_features = group_sorted[['VGS', 'VDS', 'ID']].values.flatten()\n",
    "        W = params_df.loc[params_df['MOSFET_ID'] == mosfet_id, 'W'].values[0]\n",
    "        L = params_df.loc[params_df['MOSFET_ID'] == mosfet_id, 'L'].values[0]\n",
    "        features = np.concatenate([measurement_features, [W, L]])\n",
    "        X_list.append(features)\n",
    "        mosfet_ids.append(mosfet_id)\n",
    "\n",
    "X = np.array(X_list)\n",
    "\n",
    "# Prepare target (KP) with log transformation\n",
    "params_df.set_index('MOSFET_ID', inplace=True)\n",
    "y_list = []\n",
    "for mosfet_id in mosfet_ids:\n",
    "    kp = params_df.loc[mosfet_id, 'KP']\n",
    "    y_list.append(np.log1p(kp))\n",
    "y = np.array(y_list).reshape(-1, 1)\n",
    "\n",
    "print(\"Input shape (X):\", X.shape)\n",
    "print(\"Target shape (y):\", y.shape)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the inputs and outputs\n",
    "input_scaler = StandardScaler()\n",
    "X_train_scaled = input_scaler.fit_transform(X_train)\n",
    "X_test_scaled = input_scaler.transform(X_test)\n",
    "\n",
    "output_scaler = StandardScaler()\n",
    "y_train_scaled = output_scaler.fit_transform(y_train)\n",
    "y_test_scaled = output_scaler.transform(y_test)\n",
    "\n",
    "# Cell 2: Clear Previous Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# K.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Cell 3: Enhanced Model Definition with Fixed Learning Rate\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "print(\"Input dimension:\", input_dim)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Use a fixed learning rate compatible with ReduceLROnPlateau\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# Cell 4: Model Training with Early Stopping and Learning Rate Reduction\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Cell 5: Plotting Training History\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Cell 6: Evaluation with Inverse Transformation\n",
    "predictions_scaled = model.predict(X_test_scaled)\n",
    "predictions = np.expm1(output_scaler.inverse_transform(predictions_scaled))\n",
    "y_test_original = np.expm1(output_scaler.inverse_transform(y_test_scaled))\n",
    "\n",
    "epsilon = 1e-10\n",
    "percentage_errors = np.abs((predictions - y_test_original) / (y_test_original + epsilon)) * 100\n",
    "mean_percentage_errors = np.mean(percentage_errors, axis=0)\n",
    "\n",
    "parameter_names = [\"KP\"]\n",
    "print(\"\\nOverall Percentage Errors:\")\n",
    "for i, param in enumerate(parameter_names):\n",
    "    print(f\"{param}: {mean_percentage_errors[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save the Model\n",
    "#model.save('mosfet_level3_kp_model_v2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Without Clipping:\n",
      "Mean Percentage Error: 147.62%\n",
      "R² Score: -5348.5372\n",
      "MSE: 0.000090921313411\n",
      "RMSE: 0.0095352668\n",
      "\n",
      "With Bottom Clipping:\n",
      "Mean Percentage Error: 6.72%\n",
      "R² Score: 0.9711\n",
      "MSE: 0.000000000490583\n",
      "RMSE: 0.0000221491\n",
      "\n",
      "Summary Stats:\n",
      "True KP min/max/mean: 5.000679756356907e-05 0.0004999509434650001 0.0002761488353345906\n",
      "Unclipped Predictions min/max/mean: -1.0 0.00051204965 0.00018443541\n",
      "Clipped Predictions min/max/mean: 5e-05 0.00051204965 0.00027534904\n",
      "\n",
      "Clipping Details (out of 11000 samples):\n",
      "Values clipped below 5e-05: 1 (0.01%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "# Define the minimum KP for clipping (only bottom clipping)\n",
    "KP_MIN = 50e-6  # 0.000050, from your dataset range\n",
    "\n",
    "# Function to compute and print metrics\n",
    "def compute_metrics(y_true, y_pred, label):\n",
    "    epsilon = 1e-10  # Small value to avoid division by zero\n",
    "    percentage_errors = np.abs((y_pred - y_true) / (y_true + epsilon)) * 100\n",
    "    mpe = np.mean(percentage_errors)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"Mean Percentage Error: {mpe:.2f}%\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    print(f\"MSE: {mse:.15f}\")\n",
    "    print(f\"RMSE: {rmse:.10f}\")\n",
    "    return percentage_errors\n",
    "\n",
    "# Get predictions\n",
    "predictions_scaled = model.predict(X_test_scaled)\n",
    "predictions_unclipped = np.expm1(output_scaler.inverse_transform(predictions_scaled))\n",
    "y_test_original = np.expm1(output_scaler.inverse_transform(y_test_scaled))\n",
    "\n",
    "# Total number of test samples\n",
    "n_samples = len(y_test_original)\n",
    "\n",
    "# Compute metrics without clipping\n",
    "percentage_errors_unclipped = compute_metrics(y_test_original, predictions_unclipped, \"Without Clipping\")\n",
    "\n",
    "# Clip predictions only from below (values < KP_MIN)\n",
    "predictions_clipped = np.maximum(predictions_unclipped, KP_MIN)\n",
    "percentage_errors_clipped = compute_metrics(y_test_original, predictions_clipped, \"With Bottom Clipping\")\n",
    "\n",
    "# Clipping statistics (only tracking below KP_MIN)\n",
    "n_clipped_below = np.sum(predictions_unclipped < KP_MIN)\n",
    "pct_clipped_below = (n_clipped_below / n_samples) * 100\n",
    "\n",
    "# Summary stats with clipping details\n",
    "print(\"\\nSummary Stats:\")\n",
    "print(\"True KP min/max/mean:\", y_test_original.min(), y_test_original.max(), y_test_original.mean())\n",
    "print(\"Unclipped Predictions min/max/mean:\", predictions_unclipped.min(), predictions_unclipped.max(), predictions_unclipped.mean())\n",
    "print(\"Clipped Predictions min/max/mean:\", predictions_clipped.min(), predictions_clipped.max(), predictions_clipped.mean())\n",
    "print(f\"\\nClipping Details (out of {n_samples} samples):\")\n",
    "print(f\"Values clipped below {KP_MIN}: {n_clipped_below} ({pct_clipped_below:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOSFET_NN_mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
